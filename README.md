# STRIDE: Physics-Guided Null-Space Diffusion with Sparse Masking for Corrective Sparse-View CT Reconstruction
[![arXiv](https://img.shields.io/badge/arXiv-2509.05992-b31b1b.svg)](https://arxiv.org/abs/2509.05992)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
This repository contains the PyTorch implementation of the paper **"Physics-Guided Null-Space Diffusion with Sparse Masking for Corrective Sparse-View CT Reconstruction"**.
> **Code Availability:** The source code is available at [https://github.com/yqx7150/STRIDE](https://github.com/yqx7150/STRIDE).

## Abstract
Current models based on deep learning for low-dose CT denoising rely heavily on paired data and generalize poorly. Even the more concerned diffusion models need to learn the distribution of clean data for reconstruction, which is difficult to satisfy in medical clinical applications. At the same time, self-supervised-based methods face the challenge of significant degradation of generalizability of models pre-trained for the current dose to expand to other doses. To address these issues, this work proposes a novel method of TUnable-geneRalizatioN Diffusion (TurnDiff) powered by self-supervised contextual sub-data for low-dose CT reconstruction. Firstly, a contextual subdata self-enhancing similarity strategy is designed for denoising centered on the LDCT projection domain, which provides an initial prior for the subsequent progress. Subsequently, the initial prior is used to combine knowledge distillation with a deep combination of latent diffusion models for optimizing image details. The pre-trained model is used for inference reconstruction, and the pixellevel self-correcting fusion technique is proposed for finegrained reconstruction of the image domain to enhance the image fidelity, using the initial prior and the LDCT image as a guide. In addition, the technique is flexibly applied to the generalization of upper and lower doses or even unseen doses. Dual-domain strategy cascade for self-supervised LDCT denoising, TurnDiff requires only LDCT projection domain data for training and testing. Comprehensive evaluation on both benchmark datasets and real-world data demonstrates that TurnDiff consistently outperforms stateof-the-art methods in both reconstruction and generalization.

## Key Features
* [cite_start]**Range-Null Space Decomposition (RND):** Explicitly decomposes the CT image into a known component (derived from sparse projections) and an unknown null-space component (recovered by the diffusion model), ensuring strict physics constraints ($Ax=y$).
* [cite_start]**Temporally Varying Reweighting (TCRG):** Unlike static guidance, this strategy dynamically computes the optimal correction weight $\lambda_t$ at each timestep using linear regression, balancing the trade-off between the diffusion prior and data consistency.
* [cite_start]**Sparse Masking Training:** Incorporates random sparse masks during training to simulate the sparse-view acquisition process, enhancing the model's ability to handle missing projection data.
* [cite_start]**Corrective Sampling:** Mitigates distribution shifts and "hallucinations" by actively correcting the sampling trajectory towards the measurement subspace.
